{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d56055c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Notebook: 11_Pit_Stop_Power_Analysis.ipynb\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# --- 1. Configure and Start Spark Session ---\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"F1 Pit Stop Power Analysis\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"minioadmin\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"minioadmin\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Spark session created!\")\n",
    "\n",
    "# --- 2. Load All 24 Races ---\n",
    "laps_dir = \"s3a://raw-data/laps/\"\n",
    "print(f\"Loading all lap data from {laps_dir}...\")\n",
    "df = spark.read.parquet(laps_dir)\n",
    "\n",
    "# --- 3. Clean and Prepare Data ---\n",
    "# We need to know which race each lap is from.\n",
    "# We can get this from the file name.\n",
    "df_with_race = df.withColumn(\"RaceName\", F.regexp_extract(F.input_file_name(), r\"(\\w+)\\.parquet$\", 1))\n",
    "\n",
    "# Filter for \"good\" laps\n",
    "clean_df = df_with_race.filter(\n",
    "    (F.col('IsAccurate') == True) &\n",
    "    (F.col('LapTime').isNotNull()) &\n",
    "    (F.col('Stint').isNotNull()) &\n",
    "    (F.col('Compound').isNotNull()) &\n",
    "    (F.col('Compound') != 'UNKNOWN')\n",
    ").na.drop()\n",
    "\n",
    "print(f\"Total clean laps loaded: {clean_df.count()}\")\n",
    "\n",
    "# --- 4. Use Window Function to Find Pit Laps ---\n",
    "print(\"Analyzing all laps to find pit stops...\")\n",
    "\n",
    "# We define a \"Window\" or \"Context\" for Spark.\n",
    "# This tells Spark to group data by Race and Driver, and order it by Lap.\n",
    "lap_window = Window.partitionBy(\"RaceName\", \"Driver\").orderBy(\"LapNumber\")\n",
    "\n",
    "# Now we \"slide\" this window over the data.\n",
    "# We ask Spark to get the value from the *previous* row (\"lag\")\n",
    "# for 'Stint' and 'LapTime'.\n",
    "laps_with_history_df = clean_df.withColumn(\"Prev_Stint\", F.lag(\"Stint\").over(lap_window)) \\\n",
    "                               .withColumn(\"Prev_LapTime\", F.lag(\"LapTime\").over(lap_window))\n",
    "\n",
    "# --- 5. Isolate the \"Post-Pit\" Laps ---\n",
    "# A \"post-pit lap\" is the first lap of a new stint.\n",
    "# We find it by comparing the 'Stint' to the 'Prev_Stint'.\n",
    "post_pit_laps_df = laps_with_history_df.filter(\n",
    "    (F.col(\"Stint\") != F.col(\"Prev_Stint\")) &\n",
    "    (F.col(\"Prev_Stint\").isNotNull())\n",
    ")\n",
    "\n",
    "print(f\"Found {post_pit_laps_df.count()} post-pit laps (new tire laps) across the season.\")\n",
    "\n",
    "# --- 6. Calculate the \"Pit Stop Power\" Delta ---\n",
    "# 'LapTime' is the new, fast lap on fresh tires.\n",
    "# 'Prev_LapTime' is the old, slow lap on worn tires.\n",
    "# Delta = Old Lap - New Lap (A positive number means we got faster)\n",
    "delta_df = post_pit_laps_df.withColumn(\n",
    "    \"Time_Delta\", \n",
    "    F.col(\"Prev_LapTime\") - F.col(\"LapTime\")\n",
    ")\n",
    "\n",
    "# Show some examples\n",
    "print(\"Sample of pit stop deltas (positive = faster):\")\n",
    "delta_df.select(\"RaceName\", \"Driver\", \"Compound\", \"LapTime\", \"Prev_LapTime\", \"Time_Delta\").show(10)\n",
    "\n",
    "# --- 7. Aggregate the Final Result ---\n",
    "print(\"Calculating average time gained per compound...\")\n",
    "final_analysis = delta_df.groupBy(\"Compound\") \\\n",
    "    .agg(\n",
    "        F.avg(\"Time_Delta\").alias(\"Average_Time_Gained\"),\n",
    "        F.count(\"Time_Delta\").alias(\"Total_PitStops\")\n",
    "    ) \\\n",
    "    .orderBy(\"Average_Time_Gained\", ascending=False)\n",
    "\n",
    "# --- 8. Show and Save the Final \"Product\" ---\n",
    "print(\"\\n--- FINAL ANALYSIS: Pit Stop Power (Seconds) ---\")\n",
    "final_analysis.show()\n",
    "\n",
    "# Save this final analysis to your processed data bucket\n",
    "output_path = \"s3a://processed-data/final_analysis/pit_stop_power.parquet\"\n",
    "print(f\"Saving final analysis to {output_path}...\")\n",
    "final_analysis.write.mode(\"overwrite\").parquet(output_path)\n",
    "\n",
    "print(\"--- Analysis Complete and Saved! ---\")\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
