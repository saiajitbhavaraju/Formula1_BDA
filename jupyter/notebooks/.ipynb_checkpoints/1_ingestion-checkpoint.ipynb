{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e5c7a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buckets already exist.\n",
      "Loading session data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Bahrain Grand Prix - Race [v3.6.1]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for lap_count\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "req            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '11', '55', '16', '63', '4', '44', '81', '14', '18', '24', '20', '3', '22', '23', '27', '31', '10', '77', '2']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dtypes (sample):\n",
      " Time                  timedelta64[ns]\n",
      "Driver                         object\n",
      "DriverNumber                   object\n",
      "LapTime               timedelta64[ns]\n",
      "LapNumber                     float64\n",
      "Stint                         float64\n",
      "PitOutTime            timedelta64[ns]\n",
      "PitInTime             timedelta64[ns]\n",
      "Sector1Time           timedelta64[ns]\n",
      "Sector2Time           timedelta64[ns]\n",
      "Sector3Time           timedelta64[ns]\n",
      "Sector1SessionTime    timedelta64[ns]\n",
      "Sector2SessionTime    timedelta64[ns]\n",
      "Sector3SessionTime    timedelta64[ns]\n",
      "SpeedI1                       float64\n",
      "dtype: object\n",
      "\n",
      "Converting 11 timedelta columns to seconds (float):\n",
      "['Time', 'LapTime', 'PitOutTime', 'PitInTime', 'Sector1Time', 'Sector2Time', 'Sector3Time', 'Sector1SessionTime', 'Sector2SessionTime', 'Sector3SessionTime', 'LapStartTime']\n",
      "\n",
      "Converting 1 datetime columns to string:\n",
      "['LapStartDate']\n",
      "\n",
      "New dtypes (sample):\n",
      " Time                  float64\n",
      "Driver                 object\n",
      "DriverNumber           object\n",
      "LapTime               float64\n",
      "LapNumber             float64\n",
      "Stint                 float64\n",
      "PitOutTime            float64\n",
      "PitInTime             float64\n",
      "Sector1Time           float64\n",
      "Sector2Time           float64\n",
      "Sector3Time           float64\n",
      "Sector1SessionTime    float64\n",
      "Sector2SessionTime    float64\n",
      "Sector3SessionTime    float64\n",
      "SpeedI1               float64\n",
      "dtype: object\n",
      "Saving laps to s3://raw-data/2024_bahrain_laps.parquet...\n",
      "Ingestion Complete!\n",
      "Ingestion Complete!\n"
     ]
    }
   ],
   "source": [
    "import fastf1\n",
    "import s3fs\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1. Configure S3 (MinIO) Connection ---\n",
    "# This uses the service name 'minio' from docker-compose\n",
    "endpoint_url = 'http://minio:9000'\n",
    "s3 = s3fs.S3FileSystem(\n",
    "    client_kwargs={'endpoint_url': endpoint_url},\n",
    "    key='minioadmin',\n",
    "    secret='minioadmin'\n",
    ")\n",
    "\n",
    "# --- 2. Create Buckets (Run once) ---\n",
    "try:\n",
    "    s3.mkdir('raw-data')\n",
    "    s3.mkdir('processed-data')\n",
    "    print(\"Buckets created!\")\n",
    "except FileExistsError:\n",
    "    print(\"Buckets already exist.\")\n",
    "\n",
    "# --- 3. Ingest Data ---\n",
    "# Enable FastF1 cache (mounted as a Docker volume)\n",
    "fastf1.Cache.enable_cache('/home/jovyan/.cache/fastf1') \n",
    "\n",
    "print(\"Loading session data...\")\n",
    "session = fastf1.get_session(2024, 'Bahrain', 'R') # Race\n",
    "session.load(telemetry=True, laps=True, weather=False)\n",
    "\n",
    "# --- 4. Get Laps and Save to MinIO as Parquet ---\n",
    "laps_df = session.laps\n",
    "\n",
    "print(\"Original dtypes (sample):\\n\", laps_df.dtypes.head(15))\n",
    "\n",
    "# === FIX 1: Convert timedelta columns to float (seconds) ===\n",
    "timedelta_cols = laps_df.select_dtypes(include=['timedelta64[ns]']).columns\n",
    "if not timedelta_cols.empty:\n",
    "    print(f\"\\nConverting {len(timedelta_cols)} timedelta columns to seconds (float):\")\n",
    "    print(list(timedelta_cols))\n",
    "    for col in timedelta_cols:\n",
    "        laps_df.loc[:, col] = laps_df[col].dt.total_seconds()\n",
    "        \n",
    "# === FIX 2: Convert datetime columns to string (ISO format) ===\n",
    "# This is the new part that fixes the error\n",
    "datetime_cols = laps_df.select_dtypes(include=['datetime64[ns]']).columns\n",
    "if not datetime_cols.empty:\n",
    "    print(f\"\\nConverting {len(datetime_cols)} datetime columns to string:\")\n",
    "    print(list(datetime_cols))\n",
    "    for col in datetime_cols:\n",
    "        # Convert to string. NaT (Not a Time) becomes 'NaT' string\n",
    "        laps_df.loc[:, col] = laps_df[col].astype(str) \n",
    "\n",
    "print(\"\\nNew dtypes (sample):\\n\", laps_df.dtypes.head(15))\n",
    "# === END FIX ===\n",
    "\n",
    "file_path = 's3://raw-data/2024_bahrain_laps.parquet'\n",
    "\n",
    "print(f\"Saving laps to {file_path}...\")\n",
    "with s3.open(file_path, 'wb') as f:\n",
    "    # === THE FIX: Force compatible Parquet format ===\n",
    "    laps_df.to_parquet(\n",
    "        f,\n",
    "        index=False,\n",
    "        version='2.4',  # Use an older, more stable Parquet version\n",
    "        coerce_timestamps='us' # Coerce all timestamps to microseconds\n",
    "    )\n",
    "    # === END FIX ===\n",
    "\n",
    "print(\"Ingestion Complete!\")\n",
    "\n",
    "print(\"Ingestion Complete!\")\n",
    "\n",
    "# You can repeat this for telemetry\n",
    "# Note: Telemetry is huge! This is your \"Big Data\"\n",
    "# car_data = session.car_data\n",
    "# ... save to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f90798-11fe-4745-badf-47ea1e1d10d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
