{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1ca2232",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session created!\n",
      "Loading all lap data from s3a://raw-data/laps/...\n",
      "Total laps loaded from all 24 races: 27050\n",
      "Cleaning data and preparing features...\n",
      "Total 'clean' laps for training: 23976\n",
      "+-------+---------+--------+------------+----------+\n",
      "|LapTime|LapNumber|TyreLife|    Compound|IsAccurate|\n",
      "+-------+---------+--------+------------+----------+\n",
      "| 97.672|      2.0|     2.0|INTERMEDIATE|      true|\n",
      "| 96.443|      3.0|     3.0|INTERMEDIATE|      true|\n",
      "| 95.105|      4.0|     4.0|INTERMEDIATE|      true|\n",
      "| 93.859|      5.0|     5.0|INTERMEDIATE|      true|\n",
      "| 92.634|      6.0|     6.0|INTERMEDIATE|      true|\n",
      "+-------+---------+--------+------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Defining ML pipeline...\n",
      "Splitting data and training the model...\n",
      "Model training complete!\n",
      "Evaluating model performance...\n",
      "+-------+-----------------+--------+--------+\n",
      "|LapTime|       prediction|Compound|TyreLife|\n",
      "+-------+-----------------+--------+--------+\n",
      "| 73.883|82.52775088951172|    SOFT|     2.0|\n",
      "| 73.977|81.01092822811611|    SOFT|    12.0|\n",
      "| 74.038|80.85924596197655|    SOFT|    13.0|\n",
      "|  74.09|80.96377783998118|    SOFT|     9.0|\n",
      "| 74.243|80.10083463127876|    SOFT|    18.0|\n",
      "| 74.308|87.33516032145187|    HARD|     4.0|\n",
      "| 74.353|79.79747009899964|    SOFT|    20.0|\n",
      "|  74.43|87.03179578917275|    HARD|     6.0|\n",
      "|  74.48|81.61765729267435|    SOFT|     8.0|\n",
      "| 74.488|84.04530085451648|    HARD|    29.0|\n",
      "+-------+-----------------+--------+--------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Model Performance (RMSE): 10.251263717623072\n",
      "This means our model's predictions are, on average, off by {rmse} seconds.\n",
      "Saving model to s3a://processed-data/models/f1_laptime_model...\n",
      "--- ML Model Trained and Saved to MinIO! ---\n"
     ]
    }
   ],
   "source": [
    "# Notebook: 08_ML_Model_Training.ipynb\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# --- 1. Configure and Start Spark Session ---\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"F1 ML Model Training\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"minioadmin\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"minioadmin\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Spark session created!\")\n",
    "\n",
    "# --- 2. Load \"Massive\" Data from MinIO ---\n",
    "# This is the key: We read the *entire directory* as one DataFrame\n",
    "laps_dir = \"s3a://raw-data/laps/\"\n",
    "print(f\"Loading all lap data from {laps_dir}...\")\n",
    "\n",
    "df = spark.read.parquet(laps_dir)\n",
    "print(f\"Total laps loaded from all 24 races: {df.count()}\")\n",
    "\n",
    "# --- 3. Feature Engineering and Cleaning ---\n",
    "print(\"Cleaning data and preparing features...\")\n",
    "\n",
    "# Select only the columns we need\n",
    "# Label (what we predict): LapTime\n",
    "# Features (what we use to predict): LapNumber, TyreLife, Compound\n",
    "feature_df = df.select(\n",
    "    \"LapTime\", \n",
    "    \"LapNumber\", \n",
    "    \"TyreLife\", \n",
    "    \"Compound\",\n",
    "    \"IsAccurate\" # For filtering\n",
    ")\n",
    "\n",
    "# Clean the data\n",
    "# 1. Filter for \"good\" laps only\n",
    "clean_df = feature_df.filter(\n",
    "    (F.col('IsAccurate') == True) &\n",
    "    (F.col('LapTime').isNotNull()) &\n",
    "    (F.col('LapNumber').isNotNull()) &\n",
    "    (F.col('TyreLife').isNotNull()) &\n",
    "    (F.col('Compound').isNotNull()) &\n",
    "    (F.col('Compound') != 'UNKNOWN')\n",
    ")\n",
    "\n",
    "# 2. Drop any remaining nulls\n",
    "clean_df = clean_df.na.drop()\n",
    "\n",
    "print(f\"Total 'clean' laps for training: {clean_df.count()}\")\n",
    "clean_df.show(5)\n",
    "\n",
    "# --- 4. Define the ML Pipeline ---\n",
    "print(\"Defining ML pipeline...\")\n",
    "\n",
    "# Stage 1: Convert 'Compound' (SOFT, MEDIUM, HARD) to a number (e.g., 0.0, 1.0, 2.0)\n",
    "compound_indexer = StringIndexer(inputCol=\"Compound\", outputCol=\"CompoundIndex\")\n",
    "\n",
    "# Stage 2: Assemble all feature columns into a single \"features\" vector\n",
    "feature_cols = [\"LapNumber\", \"TyreLife\", \"CompoundIndex\"]\n",
    "vector_assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "\n",
    "# Stage 3: (Optional but good practice) Scale features\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "\n",
    "# Stage 4: Define the Machine Learning model\n",
    "# We're predicting LapTime (a number), so we use a regression model\n",
    "lr = LinearRegression(featuresCol=\"scaledFeatures\", labelCol=\"LapTime\")\n",
    "\n",
    "# Chain all stages together into a single pipeline\n",
    "pipeline = Pipeline(stages=[compound_indexer, vector_assembler, scaler, lr])\n",
    "\n",
    "# --- 5. Train the Model ---\n",
    "print(\"Splitting data and training the model...\")\n",
    "(training_data, test_data) = clean_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# This is the \"product\": the trained model\n",
    "model = pipeline.fit(training_data)\n",
    "\n",
    "print(\"Model training complete!\")\n",
    "\n",
    "# --- 6. Evaluate the Model ---\n",
    "print(\"Evaluating model performance...\")\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Show a few predictions\n",
    "predictions.select(\"LapTime\", \"prediction\", \"Compound\", \"TyreLife\").show(10)\n",
    "\n",
    "# Get the Root Mean Squared Error (RMSE)\n",
    "evaluator = RegressionEvaluator(labelCol=\"LapTime\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Model Performance (RMSE): {rmse}\")\n",
    "print(\"This means our model's predictions are, on average, off by {rmse} seconds.\")\n",
    "\n",
    "# --- 7. Save the \"Product\" (The Trained Model) ---\n",
    "model_path = \"s3a://processed-data/models/f1_laptime_model\"\n",
    "print(f\"Saving model to {model_path}...\")\n",
    "\n",
    "model.write().overwrite().save(model_path)\n",
    "\n",
    "print(\"--- ML Model Trained and Saved to MinIO! ---\")\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ad8c10-7f9c-438d-8b83-20dc7a7050bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
